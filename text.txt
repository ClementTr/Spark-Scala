
import org.apache.spark.SparkConf
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
import org.apache.spark.ml.Pipeline
import org.apache.spark.sql.SparkSession
import org.apache.spark.ml.feature.StringIndexer
import org.apache.spark.ml.classification.LogisticRegression
import org.apache.spark.ml.tuning.{ParamGridBuilder, TrainValidationSplit}
import org.apache.spark.ml.feature.{CountVectorizer, IDF, RegexTokenizer, StopWordsRemover}
import org.apache.spark.ml.feature.VectorAssembler

val df_cleaned = spark.read.load("data/train_cleaned/*.parquet")

val tokenizer = new RegexTokenizer().setPattern("\\W+").setGaps(true).setInputCol("text").setOutputCol("tokens")

val stopworder = new StopWordsRemover().setInputCol("tokens").setOutputCol("without_stopwords")

val vectorizer = new CountVectorizer().setInputCol("without_stopwords").setOutputCol("vectorize")
    
val idf = new IDF().setInputCol("vectorize").setOutputCol("tfidf")
val indexer_country = new StringIndexer().setInputCol("country2").setOutputCol("country_indexed")

val indexer_currency = new StringIndexer().setInputCol("currency2").setOutputCol("currency_indexed")

val assembler = new VectorAssembler().setInputCols(Array("tfidf", "days_campaign", "hours_prepa", "goal", "country_indexed", "currency_indexed")).setOutputCol("features")

val lr = new LogisticRegression().setElasticNetParam(0.0).setFitIntercept(true).setFeaturesCol("features").setLabelCol("final_status").setStandardization(true).setPredictionCol("predictions").setRawPredictionCol("raw_predictions").setThresholds(Array(0.7, 0.3)).setTol(1.0e-6).setMaxIter(300)

val pipeline = new Pipeline().setStages(Array(tokenizer,stopworder,vectorizer,idf,indexer_country,indexer_currency,assembler,lr))

val df_init = df_cleaned.withColumn("final_status", 'final_status.cast("Double"))
val Array(training, test) = df_init.select("text", "goal", "country2", "currency2","deadline2", "launched_at2", "days_campaign","created_at2", "hours_prepa", "final_status").randomSplit(Array(0.9, 0.1))

val paramGrid = new ParamGridBuilder().addGrid(lr.regParam, Array(scala.math.pow(10,-8),scala.math.pow(10,-6),scala.math.pow(10,-4),scala.math.pow(10,-2))).addGrid(vectorizer.minDF, Array(55.0, 75.0, 85.0, 95.0)).build()

val eval = new MulticlassClassificationEvaluator().setLabelCol("final_status").setPredictionCol("predictions").setMetricName("f1")

val trainValidationSplit = new TrainValidationSplit().setEstimator(pipeline).setEvaluator(eval).setEstimatorParamMaps(paramGrid).setTrainRatio(0.7)

val model = trainValidationSplit.fit(training)
val df_WithPredictions = model.transform(test)

val score = eval.evaluate(df_WithPredictions)
print("My score: ", score)

df_WithPredictions.groupBy("final_status","predictions").count.show()

model.save("myModelPath")
